{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "import os\n",
    "import pandas as pd\n",
    "from geo.drift_compensation import get_track_drift_rate\n",
    "from get_turn import get_turning_points, plot_changepoints, TurnAndRise, write_turnandrise_to_zarr\n",
    "import csv\n",
    "import random\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_filename_from_filepath(filepath: str) -> str:\n",
    "    # Get the filename without the extension\n",
    "    filename = os.path.splitext(os.path.basename(filepath))[0]\n",
    "    return filename\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_csv_file(filepath: str, logtag: str, n_idents: int = 0, ident_filter: List[str] = [], ident_mandatory: List[str] = []):\n",
    "    # Set up logging\n",
    "    logger = logging.getLogger(logtag)\n",
    "    logger.setLevel(logging.DEBUG)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    fh = logging.FileHandler(f'{logtag}.log')\n",
    "    fh.setLevel(logging.DEBUG)\n",
    "    fh.setFormatter(formatter)\n",
    "    logger.addHandler(fh)\n",
    "\n",
    "    # Read the file and preprocess it\n",
    "    df:pd.DataFrame = pd.read_csv(filepath, compression='gzip')\n",
    "    logger.info(f\"Read {len(df)} rows from {filepath}\")\n",
    "    df.dropna(how='any', inplace=True)\n",
    "    logger.info(f\"Dropped NaN rows, {len(df)} rows remaining\")\n",
    "    # add an ident column by concatenating df['callsign'] and df['icao24']\n",
    "    df['ident'] = (df['callsign'].str.strip()+'_'+df['icao24'].str.strip())\n",
    "    # add a column rtime that is df['time'] - df['time'].min()\n",
    "    df['rtime'] = df['time'] - df['time'].min()\n",
    "    # Drop the columns we don't need\n",
    "    df.drop(columns=['onground', 'alert', 'spi', 'squawk'], inplace=True)\n",
    "    idents = df['ident'].unique()\n",
    "    # Only keep the idents that are in the ident_filter\n",
    "    if len(ident_filter) > 0:\n",
    "        idents = [ident for ident in idents if ident in ident_filter]\n",
    "    # Choose randomly n_idents from the list\n",
    "    if n_idents > 0 and n_idents < len(idents):\n",
    "        idents = random.sample(list(idents), n_idents)\n",
    "    # Add the mandatory idents to the list\n",
    "    idents = ident_mandatory + idents\n",
    "    # Remove duplicates\n",
    "    idents = list(set(idents))\n",
    "    # Ensure idents.length = n_idents by keeping only the first n_idents\n",
    "    if n_idents > 0 and len(idents) > n_idents:\n",
    "        idents = idents[:n_idents]\n",
    "    \n",
    "    logger.info(f\"Processing {len(idents)} unique idents\")\n",
    "\n",
    "    filename = get_filename_from_filepath(filepath)\n",
    "\n",
    "    # Create a folder called filename inside the routes folder\n",
    "    os.makedirs(f'../data/osstate/routes/{filename}', exist_ok=True)\n",
    "\n",
    "    # To write dangling flights to a separate CSV file\n",
    "    with open(f'../data/osstate/dangling/{filename}.csv', 'w', newline='') as file:\n",
    "        writer = csv.writer(file)\n",
    "        writer.writerow(['filename', 'ident'])\n",
    "        for ident in idents:\n",
    "            try:\n",
    "                # Get the subdf for the ident\n",
    "                df_ident = df[df['ident'] == ident]\n",
    "                if len(df_ident) == 0:\n",
    "                    logger.error(f\"Ident {ident} not found in the dataframe\")\n",
    "                    continue\n",
    "                turns:TurnAndRise = get_turning_points(df_ident)\n",
    "                if not turns['landed']:\n",
    "                    # Aircraft not yet landed, write to a CSV file\n",
    "                    \n",
    "                    writer.writerow([filename, ident])\n",
    "                \n",
    "                write_turnandrise_to_zarr(turns, f'../data/osstate/routes/{filename}/{ident}.zarr')\n",
    "                logger.info(f\"Processed {ident}\")\n",
    "            except Exception as e:\n",
    "                logger.error(f\"Error processing {ident}: {e}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dangling_idents(filepath: str) -> List[str]:\n",
    "    filename = get_filename_from_filepath(filepath)\n",
    "    try:\n",
    "        dangling_df = pd.read_csv(f'../data/osstate/dangling/{filename}.csv')\n",
    "        return dangling_df['ident'].unique().tolist()\n",
    "    except FileNotFoundError:\n",
    "        return []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_file_list() -> List[str]:\n",
    "    # List all the files in the data folder\n",
    "    data_files = os.listdir('../data/osstate/extracted')\n",
    "    # Only keep the .csv.gz files\n",
    "    data_files = [file for file in data_files if file.endswith('.csv.gz')]\n",
    "    data_files = [f'../data/osstate/extracted/{file}' for file in data_files]\n",
    "    # Sort the files alphabetically\n",
    "    data_files.sort()\n",
    "    print(f'Found {len(data_files)} files')\n",
    "    return data_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Multiprocessing\n",
    "# ================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import multiprocessing as mp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 85 files\n",
      "Processing 21 files in thread 0Processing 21 files in thread 1\n",
      "\n",
      "Processing 21 files in thread 2\n",
      "Processing 21 files in thread 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:63: RuntimeWarning: The iteration is not making good progress, as measured by the \n",
      "  improvement from the last ten iterations.\n",
      "  c = fsolve(course_equation, c0, args=(xp, yp, zp, xn, yn, zn, crs))\n",
      "/home/user/deepflow/flow-detection/geo/drift_compensation.py:122: RuntimeWarning: invalid value encountered in arccos\n",
      "  angle = np.rad2deg(np.arccos(np.dot(n_prime, c_prime)))\n",
      "Process Process-3:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "Process Process-2:\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "Traceback (most recent call last):\n",
      "  File \"/tmp/ipykernel_3096/2632686981.py\", line 7, in process_file\n",
      "    process_csv_file(filepath=file, logtag=file, n_idents=n_idents, ident_mandatory=get_dangling_idents(file_list[index - 1]))\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_3096/2632686981.py\", line 7, in process_file\n",
      "    process_csv_file(filepath=file, logtag=file, n_idents=n_idents, ident_mandatory=get_dangling_idents(file_list[index - 1]))\n",
      "  File \"/tmp/ipykernel_3096/3935360900.py\", line 61, in process_csv_file\n",
      "    write_turnandrise_to_zarr(turns, f'../data/osstate/routes/{filename}/{ident}.zarr')\n",
      "Process Process-1:\n",
      "  File \"/tmp/ipykernel_3096/3935360900.py\", line 51, in process_csv_file\n",
      "    df_ident = df[df['ident'] == ident]\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/deepflow/flow-detection/get_turn.py\", line 204, in write_turnandrise_to_zarr\n",
      "    zarr_group.create_dataset(key, data=value)\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/zarr/hierarchy.py\", line 1111, in create_dataset\n",
      "    return self._write_op(self._create_dataset_nosync, name, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py\", line 314, in _bootstrap\n",
      "    self.run()\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/arraylike.py\", line 40, in __eq__\n",
      "    return self._cmp_method(other, operator.eq)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/series.py\", line 5799, in _cmp_method\n",
      "    res_values = ops.comparison_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/zarr/hierarchy.py\", line 952, in _write_op\n",
      "    return f(*args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py\", line 108, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"/tmp/ipykernel_3096/2632686981.py\", line 7, in process_file\n",
      "    process_csv_file(filepath=file, logtag=file, n_idents=n_idents, ident_mandatory=get_dangling_idents(file_list[index - 1]))\n",
      "  File \"/tmp/ipykernel_3096/3935360900.py\", line 51, in process_csv_file\n",
      "    df_ident = df[df['ident'] == ident]\n",
      "                  ^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/ops/common.py\", line 76, in new_method\n",
      "    return method(self, other)\n",
      "           ^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/arraylike.py\", line 40, in __eq__\n",
      "    return self._cmp_method(other, operator.eq)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/series.py\", line 5799, in _cmp_method\n",
      "    res_values = ops.comparison_op(lvalues, rvalues, op)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 346, in comparison_op\n",
      "    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/zarr/hierarchy.py\", line 1126, in _create_dataset_nosync\n",
      "    a = array(data, store=self._store, path=path, chunk_store=self._chunk_store, **kwargs)\n",
      "        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/zarr/creation.py\", line 441, in array\n",
      "    z = create(**kwargs)\n",
      "        ^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 131, in comp_method_OBJECT_ARRAY\n",
      "    result = libops.scalar_compare(x.ravel(), y, op)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "KeyboardInterrupt\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 346, in comparison_op\n",
      "    res_values = comp_method_OBJECT_ARRAY(op, lvalues, rvalues)\n",
      "                 ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/zarr/creation.py\", line 209, in create\n",
      "    init_array(\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/pandas/core/ops/array_ops.py\", line 131, in comp_method_OBJECT_ARRAY\n",
      "    result = libops.scalar_compare(x.ravel(), y, op)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/user/mambaforge/envs/tensorml/lib/python3.11/site-packages/zarr/storage.py\", line 455, in init_array\n",
      "    _init_array_metadata(\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m     p\u001b[38;5;241m.\u001b[39mstart()\n\u001b[1;32m     24\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m processes:\n\u001b[0;32m---> 25\u001b[0m     \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_parent_pid \u001b[38;5;241m==\u001b[39m os\u001b[38;5;241m.\u001b[39mgetpid(), \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a child process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_popen \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcan only join a started process\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_popen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[38;5;241m.\u001b[39mdiscard(\u001b[38;5;28mself\u001b[39m)\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/popen_fork.py:43\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     41\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;66;03m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n\u001b[0;32m---> 43\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mWNOHANG\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m==\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode\n",
      "File \u001b[0;32m~/mambaforge/envs/tensorml/lib/python3.11/multiprocessing/popen_fork.py:27\u001b[0m, in \u001b[0;36mPopen.poll\u001b[0;34m(self, flag)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 27\u001b[0m         pid, sts \u001b[38;5;241m=\u001b[39m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwaitpid\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflag\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m     29\u001b[0m         \u001b[38;5;66;03m# Child process not yet created. See #1731717\u001b[39;00m\n\u001b[1;32m     30\u001b[0m         \u001b[38;5;66;03m# e.errno == errno.ECHILD == 10\u001b[39;00m\n\u001b[1;32m     31\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def process_file(file_list, thread_number, n_idents = 2000):\n",
    "    print(f\"Processing {len(file_list)} files in thread {thread_number}\")\n",
    "    for index, file in enumerate(file_list):\n",
    "        if index == 0:\n",
    "            process_csv_file(filepath=file, logtag=file, n_idents=n_idents)\n",
    "        else:\n",
    "            process_csv_file(filepath=file, logtag=file, n_idents=n_idents, ident_mandatory=get_dangling_idents(file_list[index - 1]))\n",
    "\n",
    "do_not_allow_delete = True\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    file_list = get_data_file_list()\n",
    "    num_processes = 4\n",
    "    processes = []\n",
    "\n",
    "    # Divide the file list into num_processes chunks\n",
    "    file_list = [file_list[i:i + len(file_list) // num_processes] for i in range(0, len(file_list), len(file_list) // num_processes)]\n",
    "\n",
    "    for i in range(num_processes):\n",
    "        p = mp.Process(target=process_file, args=(file_list[i], i))\n",
    "        processes.append(p)\n",
    "        p.start()\n",
    "\n",
    "    for p in processes:\n",
    "        p.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CAUTION: DELETE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def wipe_slate():\n",
    "    # Wipe the slate clean\n",
    "    !rm -rf ../data/osstate/routes/*\n",
    "    !rm -rf ../data/osstate/dangling/*\n",
    "    !rm -rf *.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
